{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UVMwVF0ehm7"
      },
      "source": [
        "# Load modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\liisa\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary modules\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGjplVqweg9Z"
      },
      "source": [
        "# Functions for parsing, formatting and encoding data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xp7T9Yga4nw2"
      },
      "outputs": [],
      "source": [
        "def parse_pssm(pssm_filename):\n",
        "  amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "  num_aas = len(amino_acids)\n",
        "  sequence = ''\n",
        "  profile = []\n",
        "\n",
        "  # Parsing MSA frequences from a PSSM file \n",
        "  with open(pssm_filename) as pssm:\n",
        "    pssm_lines = pssm.readlines()\n",
        "    for line in pssm_lines[3:-6]:                 # First iterates over lines\n",
        "      profile_line = []\n",
        "      for n in line.rstrip().split()[22:-2]:      # Then over n in line \n",
        "        profile_line.append(float(n)/100)         # Converts the values to a scale of 0 to 1\n",
        "      profile.append(profile_line)\n",
        "      sequence += line[6]                         # Fetches the protein sequence: every 6th character in given line n\n",
        "\n",
        "\n",
        "  # One-hot encoding the protein sequence\n",
        "  encoding = np.zeros((len(sequence), num_aas))   # Initialises a 2D array of zeros\n",
        "  for i, aa in enumerate(sequence):               # Returns an iterator that produces tuples containing both the index and aa\n",
        "    if aa in amino_acids:\n",
        "      index = amino_acids.index(aa)               # Finds corresponding index at aa string \n",
        "      encoding[i, index] = 1                      # 0 is replaced with 1 in the array, at position: seq index x aa string index\n",
        "    else: encoding[i, :] = 0.05                   # If aa not found in file, fill the entire row with 0.05 to represent unknown/invalid aa\n",
        "\n",
        "  return encoding, profile\n",
        "\n",
        "\n",
        "# Parsing the DSSP labels\n",
        "def parse_dssp(dssp_filename):\n",
        "\tss = ''\n",
        "\twith open(dssp_filename) as dssp:\n",
        "\t\tdssp.readline()\n",
        "\t\tss = dssp.readline().rstrip()\n",
        "\treturn ss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Function for fetching appropriate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_data(window, cv=False, train=True):\n",
        "  ss_map = {'H':[1,0,0], 'E':[0,1,0], 'C':[0,0,1], '-':[0,0,1]}\n",
        "\n",
        "  # Make sure that window is an odd integer\n",
        "  assert type(window) == int, 'Error: window must be an integer!'\n",
        "  assert window%2!=0, 'Error: window must be an ODD integer!'\n",
        "\n",
        "\n",
        "  # Selecting which data to fetch (training or blind test) and loading the right list of ids\n",
        "  if not cv:\n",
        "    path = 'C:/Users/liisa/OneDrive/Dokumendid/ROOTSI/SU/Bioinformatics/Project/protein-ss-pred-master/data/blindTest/'\n",
        "    id_list = [line.rstrip() for line in open(path+'list.txt')]\n",
        "    print ('Test data is obtained:')\n",
        "  else:\n",
        "    cv = str(cv)\n",
        "    path = 'C:/Users/liisa/OneDrive/Dokumendid/ROOTSI/SU/Bioinformatics/Project/protein-ss-pred-master/data/training/'\n",
        "    if train:\n",
        "      id_list = [line.rstrip() for line in open(path+'/cv/train'+cv+'.txt')]           # Using list comprehension to store train set id-s\n",
        "      print ('Train partition of cross-validation set {} is obtained:'.format(cv))\n",
        "    else:\n",
        "      id_list = [line.rstrip() for line in open(path+'/cv/test'+cv+'.txt')]\n",
        "      print ('Test partition of cross-validation set {} is obtained:'.format(cv))\n",
        "\n",
        "  X, Y = [], []\n",
        "  for id in id_list:\n",
        "    # Fetching the input features, using list comprehension to store in list x\n",
        "    id = id.replace(\":\", \"_\")\n",
        "    sequence, profile = np.array(parse_pssm(path+'/pssm/'+id+'.pssm'))                 # sequence = one-hot encoded sequence\n",
        "    x = np.concatenate((sequence, profile), axis=-1)                        \n",
        " \n",
        "    # Fetching, encoding labels, storing in array y\n",
        "    ss = parse_dssp(path+'/dssp/'+id+'.dssp')\n",
        "    y = np.array([ss_map[c] for c in ss])\n",
        "\n",
        "    # Adding (window-1)/2 padding on both sequence sides\n",
        "    # Creating windows for first and last positions\n",
        "    side = int((window-1)/2)\n",
        "    x_pad = np.zeros((side, 40))\n",
        "    x = np.concatenate((x_pad, x, x_pad), axis=0)\n",
        "\n",
        "    # Extracting all windows:\n",
        "    # For each index i in the range from side to len(x)-side-1, it creates a window centered at position i\n",
        "    # Each window is extracted as a subarray of x from index i-side to i+side+1\n",
        "    X += [x[i-side:i+side+1,:] for i in range(side, len(x)-side-1)]                   \n",
        "    Y += [y[i,:] for i in range(len(y))]                                              # Corresponding labels for Y\n",
        "    X.append(x[-2*side-1:,:])                                                         # Extracts a window of size 2*side+1 from beginning of sequence and appends to X\n",
        "\n",
        "  return np.array(X), np.array(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYlIbZ5FfC3h"
      },
      "source": [
        "# Declare and train a neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\liisa\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 680)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               174336    \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 256)               1024      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 32)                128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 219587 (857.76 KB)\n",
            "Trainable params: 218627 (854.01 KB)\n",
            "Non-trainable params: 960 (3.75 KB)\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From c:\\Users\\liisa\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "window = 17\n",
        "input_shape = (window, 40)\n",
        "num_classes = 3\n",
        "\n",
        "model = keras.Sequential([\n",
        "        keras.Input(shape=input_shape),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(256, activation=\"leaky_relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(128, activation=\"leaky_relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(64, activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(32, activation=\"relu\"),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "model.summary() \n",
        "model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5PA_WpVexzO"
      },
      "source": [
        "# Fetch data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds6JWBFpUSrv",
        "outputId": "0b0a5297-6f93-4eae-a179-37d4a3c64b1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train partition of cross-validation set 1 is obtained:\n",
            "(157415, 17, 40) (157415, 3)\n",
            "Test partition of cross-validation set 1 is obtained:\n",
            "(40729, 17, 40) (40729, 3)\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From c:\\Users\\liisa\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\liisa\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "277/277 [==============================] - 4s 9ms/step - loss: 0.9518 - accuracy: 0.5743 - val_loss: 0.7157 - val_accuracy: 0.7080\n",
            "Epoch 2/10\n",
            "277/277 [==============================] - 2s 8ms/step - loss: 0.7530 - accuracy: 0.6861 - val_loss: 0.6655 - val_accuracy: 0.7273\n",
            "Epoch 3/10\n",
            "277/277 [==============================] - 2s 8ms/step - loss: 0.7243 - accuracy: 0.7015 - val_loss: 0.6560 - val_accuracy: 0.7318\n",
            "Epoch 4/10\n",
            "277/277 [==============================] - 2s 8ms/step - loss: 0.7006 - accuracy: 0.7118 - val_loss: 0.6343 - val_accuracy: 0.7423\n",
            "Epoch 5/10\n",
            "277/277 [==============================] - 2s 8ms/step - loss: 0.6757 - accuracy: 0.7237 - val_loss: 0.6132 - val_accuracy: 0.7493\n",
            "Epoch 6/10\n",
            "277/277 [==============================] - 2s 9ms/step - loss: 0.6505 - accuracy: 0.7346 - val_loss: 0.6012 - val_accuracy: 0.7531\n",
            "Epoch 7/10\n",
            "277/277 [==============================] - 2s 8ms/step - loss: 0.6337 - accuracy: 0.7417 - val_loss: 0.5891 - val_accuracy: 0.7578\n",
            "Epoch 8/10\n",
            "277/277 [==============================] - 2s 8ms/step - loss: 0.6199 - accuracy: 0.7484 - val_loss: 0.5833 - val_accuracy: 0.7624\n",
            "Epoch 9/10\n",
            "277/277 [==============================] - 2s 9ms/step - loss: 0.6069 - accuracy: 0.7535 - val_loss: 0.5734 - val_accuracy: 0.7668\n",
            "Epoch 10/10\n",
            "277/277 [==============================] - 2s 9ms/step - loss: 0.5948 - accuracy: 0.7586 - val_loss: 0.5699 - val_accuracy: 0.7658\n",
            "1273/1273 [==============================] - 1s 1ms/step - loss: 0.5959 - accuracy: 0.7536\n",
            "Fold 1: Loss = 0.6, Accuracy = 0.75\n",
            "Train partition of cross-validation set 2 is obtained:\n",
            "(158838, 17, 40) (158838, 3)\n",
            "Test partition of cross-validation set 2 is obtained:\n",
            "(39306, 17, 40) (39306, 3)\n",
            "Epoch 1/10\n",
            "280/280 [==============================] - 2s 9ms/step - loss: 0.6038 - accuracy: 0.7551 - val_loss: 0.5637 - val_accuracy: 0.7673\n",
            "Epoch 2/10\n",
            "280/280 [==============================] - 2s 9ms/step - loss: 0.5887 - accuracy: 0.7612 - val_loss: 0.5612 - val_accuracy: 0.7672\n",
            "Epoch 3/10\n",
            "280/280 [==============================] - 2s 9ms/step - loss: 0.5800 - accuracy: 0.7652 - val_loss: 0.5573 - val_accuracy: 0.7701\n",
            "Epoch 4/10\n",
            "280/280 [==============================] - 3s 9ms/step - loss: 0.5700 - accuracy: 0.7690 - val_loss: 0.5559 - val_accuracy: 0.7683\n",
            "Epoch 5/10\n",
            "280/280 [==============================] - 2s 9ms/step - loss: 0.5646 - accuracy: 0.7725 - val_loss: 0.5535 - val_accuracy: 0.7717\n",
            "Epoch 6/10\n",
            "280/280 [==============================] - 2s 9ms/step - loss: 0.5573 - accuracy: 0.7746 - val_loss: 0.5547 - val_accuracy: 0.7700\n",
            "Epoch 7/10\n",
            "280/280 [==============================] - 2s 9ms/step - loss: 0.5490 - accuracy: 0.7786 - val_loss: 0.5550 - val_accuracy: 0.7698\n",
            "Epoch 8/10\n",
            "280/280 [==============================] - 3s 9ms/step - loss: 0.5432 - accuracy: 0.7816 - val_loss: 0.5530 - val_accuracy: 0.7717\n",
            "Epoch 9/10\n",
            "280/280 [==============================] - 3s 9ms/step - loss: 0.5391 - accuracy: 0.7832 - val_loss: 0.5513 - val_accuracy: 0.7730\n",
            "Epoch 10/10\n",
            "280/280 [==============================] - 2s 9ms/step - loss: 0.5325 - accuracy: 0.7852 - val_loss: 0.5528 - val_accuracy: 0.7717\n",
            "1229/1229 [==============================] - 1s 1ms/step - loss: 0.5501 - accuracy: 0.7729\n",
            "Fold 2: Loss = 0.55, Accuracy = 0.77\n",
            "Train partition of cross-validation set 3 is obtained:\n",
            "(158463, 17, 40) (158463, 3)\n",
            "Test partition of cross-validation set 3 is obtained:\n",
            "(39681, 17, 40) (39681, 3)\n",
            "Epoch 1/10\n",
            "279/279 [==============================] - 3s 10ms/step - loss: 0.5473 - accuracy: 0.7784 - val_loss: 0.5463 - val_accuracy: 0.7764\n",
            "Epoch 2/10\n",
            "279/279 [==============================] - 2s 9ms/step - loss: 0.5376 - accuracy: 0.7833 - val_loss: 0.5466 - val_accuracy: 0.7748\n",
            "Epoch 3/10\n",
            "279/279 [==============================] - 2s 9ms/step - loss: 0.5301 - accuracy: 0.7862 - val_loss: 0.5475 - val_accuracy: 0.7751\n",
            "Epoch 4/10\n",
            "279/279 [==============================] - 2s 9ms/step - loss: 0.5227 - accuracy: 0.7880 - val_loss: 0.5500 - val_accuracy: 0.7774\n",
            "Epoch 5/10\n",
            "279/279 [==============================] - 2s 9ms/step - loss: 0.5196 - accuracy: 0.7908 - val_loss: 0.5488 - val_accuracy: 0.7747\n",
            "Epoch 6/10\n",
            "279/279 [==============================] - 2s 9ms/step - loss: 0.5119 - accuracy: 0.7942 - val_loss: 0.5554 - val_accuracy: 0.7742\n",
            "Epoch 7/10\n",
            "279/279 [==============================] - 2s 9ms/step - loss: 0.5098 - accuracy: 0.7947 - val_loss: 0.5508 - val_accuracy: 0.7742\n",
            "Epoch 8/10\n",
            "279/279 [==============================] - 2s 9ms/step - loss: 0.5041 - accuracy: 0.7975 - val_loss: 0.5501 - val_accuracy: 0.7762\n",
            "Epoch 9/10\n",
            "279/279 [==============================] - 2s 9ms/step - loss: 0.5008 - accuracy: 0.7992 - val_loss: 0.5535 - val_accuracy: 0.7736\n",
            "Epoch 10/10\n",
            "279/279 [==============================] - 2s 9ms/step - loss: 0.4977 - accuracy: 0.7996 - val_loss: 0.5551 - val_accuracy: 0.7729\n",
            "1241/1241 [==============================] - 1s 1ms/step - loss: 0.5274 - accuracy: 0.7849\n",
            "Fold 3: Loss = 0.53, Accuracy = 0.78\n",
            "Train partition of cross-validation set 4 is obtained:\n",
            "(159359, 17, 40) (159359, 3)\n",
            "Test partition of cross-validation set 4 is obtained:\n",
            "(38785, 17, 40) (38785, 3)\n",
            "Epoch 1/10\n",
            "281/281 [==============================] - 3s 10ms/step - loss: 0.5233 - accuracy: 0.7890 - val_loss: 0.5345 - val_accuracy: 0.7853\n",
            "Epoch 2/10\n",
            "281/281 [==============================] - 3s 9ms/step - loss: 0.5135 - accuracy: 0.7935 - val_loss: 0.5344 - val_accuracy: 0.7844\n",
            "Epoch 3/10\n",
            "281/281 [==============================] - 3s 9ms/step - loss: 0.5082 - accuracy: 0.7956 - val_loss: 0.5381 - val_accuracy: 0.7820\n",
            "Epoch 4/10\n",
            "281/281 [==============================] - 3s 9ms/step - loss: 0.5046 - accuracy: 0.7974 - val_loss: 0.5406 - val_accuracy: 0.7802\n",
            "Epoch 5/10\n",
            "281/281 [==============================] - 3s 9ms/step - loss: 0.5011 - accuracy: 0.7990 - val_loss: 0.5388 - val_accuracy: 0.7778\n",
            "Epoch 6/10\n",
            "281/281 [==============================] - 3s 9ms/step - loss: 0.4960 - accuracy: 0.8002 - val_loss: 0.5424 - val_accuracy: 0.7799\n",
            "Epoch 7/10\n",
            "281/281 [==============================] - 3s 9ms/step - loss: 0.4931 - accuracy: 0.8024 - val_loss: 0.5415 - val_accuracy: 0.7797\n",
            "Epoch 8/10\n",
            "281/281 [==============================] - 3s 9ms/step - loss: 0.4917 - accuracy: 0.8023 - val_loss: 0.5391 - val_accuracy: 0.7805\n",
            "Epoch 9/10\n",
            "281/281 [==============================] - 3s 9ms/step - loss: 0.4845 - accuracy: 0.8066 - val_loss: 0.5419 - val_accuracy: 0.7786\n",
            "Epoch 10/10\n",
            "281/281 [==============================] - 3s 9ms/step - loss: 0.4848 - accuracy: 0.8054 - val_loss: 0.5443 - val_accuracy: 0.7793\n",
            "1213/1213 [==============================] - 1s 1ms/step - loss: 0.4782 - accuracy: 0.8044\n",
            "Fold 4: Loss = 0.48, Accuracy = 0.8\n",
            "Train partition of cross-validation set 5 is obtained:\n",
            "(158501, 17, 40) (158501, 3)\n",
            "Test partition of cross-validation set 5 is obtained:\n",
            "(39643, 17, 40) (39643, 3)\n",
            "Epoch 1/10\n",
            "279/279 [==============================] - 3s 10ms/step - loss: 0.5061 - accuracy: 0.7975 - val_loss: 0.5366 - val_accuracy: 0.7801\n",
            "Epoch 2/10\n",
            "279/279 [==============================] - 3s 9ms/step - loss: 0.4974 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7805\n",
            "Epoch 3/10\n",
            "279/279 [==============================] - 3s 9ms/step - loss: 0.4931 - accuracy: 0.8018 - val_loss: 0.5418 - val_accuracy: 0.7783\n",
            "Epoch 4/10\n",
            "279/279 [==============================] - 3s 9ms/step - loss: 0.4905 - accuracy: 0.8026 - val_loss: 0.5423 - val_accuracy: 0.7778\n",
            "Epoch 5/10\n",
            "279/279 [==============================] - 2s 9ms/step - loss: 0.4823 - accuracy: 0.8068 - val_loss: 0.5455 - val_accuracy: 0.7780\n",
            "Epoch 6/10\n",
            "279/279 [==============================] - 3s 9ms/step - loss: 0.4808 - accuracy: 0.8060 - val_loss: 0.5400 - val_accuracy: 0.7778\n",
            "Epoch 7/10\n",
            "279/279 [==============================] - 3s 9ms/step - loss: 0.4791 - accuracy: 0.8074 - val_loss: 0.5454 - val_accuracy: 0.7786\n",
            "Epoch 8/10\n",
            "279/279 [==============================] - 3s 9ms/step - loss: 0.4751 - accuracy: 0.8091 - val_loss: 0.5466 - val_accuracy: 0.7764\n",
            "Epoch 9/10\n",
            "279/279 [==============================] - 3s 9ms/step - loss: 0.4730 - accuracy: 0.8092 - val_loss: 0.5494 - val_accuracy: 0.7741\n",
            "Epoch 10/10\n",
            "279/279 [==============================] - 3s 9ms/step - loss: 0.4701 - accuracy: 0.8128 - val_loss: 0.5523 - val_accuracy: 0.7776\n",
            "1239/1239 [==============================] - 1s 1ms/step - loss: 0.4573 - accuracy: 0.8146\n",
            "Fold 5: Loss = 0.46, Accuracy = 0.81\n"
          ]
        }
      ],
      "source": [
        "models = []\n",
        "for fold in range(1, 6):\n",
        "    # Loading training and testing data for the current fold\n",
        "    x_train, y_train = fetch_data(window, cv=fold, train=True)\n",
        "    print(x_train.shape, y_train.shape)\n",
        "    x_test, y_test = fetch_data(window, cv=fold, train=False)\n",
        "    print(x_test.shape, y_test.shape)\n",
        "\n",
        "    # Training model on the training data\n",
        "    history = model.fit(x_train, y_train, epochs=10, batch_size=512, validation_split=0.1)\n",
        "    \n",
        "    # Evaluating model on the testing data\n",
        "    loss, accuracy = model.evaluate(x_test, y_test)\n",
        "    models.append(model)\n",
        "    \n",
        "    \n",
        "    print(\"Fold {0}: Loss = {1}, Accuracy = {2}\".format(fold, round(loss,2), round(accuracy,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOrk_Vu4fJFP"
      },
      "source": [
        "# Fetch blind test data, use fitted model to get predictions, and evaluate predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7ryTi-JX3fG",
        "outputId": "44127463-1157-4dc7-8f7d-f96e4df98a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test data is obtained:\n",
            "(62136, 17, 40) (62136, 3)\n"
          ]
        }
      ],
      "source": [
        "x_blind_test, y_blind_test = fetch_data(window, cv=False, train=False)\n",
        "print(x_blind_test.shape, y_blind_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1942/1942 [==============================] - 2s 984us/step\n",
            "Accuracy:  0.75\n",
            "Secondary Structure Class: H, F1-score: 0.79\n",
            "Secondary Structure Class: E, F1-score: 0.7\n",
            "Secondary Structure Class: C, F1-score: 0.74\n"
          ]
        }
      ],
      "source": [
        "trained_model = models[4]\n",
        "trained_model.save('C:/Users/liisa/OneDrive/Dokumendid/ROOTSI/SU/Bioinformatics/Project/trained_FCNN.keras')\n",
        "predictions = trained_model.predict(x_blind_test)\n",
        "\n",
        "# Reporting model's accuracy\n",
        "print(\"Accuracy: \", round(accuracy_score(np.argmax(y_blind_test, axis=1), np.argmax(predictions, axis=1)),2))\n",
        "\n",
        "# Converting one-hot encoded labels back to categorical labels\n",
        "y_blind_test_cat = np.argmax(y_blind_test, axis=1)\n",
        "predictions_cat = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Calculating F1 score for each class\n",
        "F1_scores = f1_score(y_blind_test_cat, predictions_cat, average=None)\n",
        "\n",
        "ss_labels = ['H', 'E', 'C']\n",
        "# Printing F1 scores for each class\n",
        "for label, score in zip(ss_labels, F1_scores):\n",
        "    print(\"Secondary Structure Class: {0}, F1-score: {1}\".format(label,round(score,2)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
